\section{Profiling and performance analysis}
\label{sec:prof}

Omnipath
Accurate timing
Other metrics â€“ flops of various precisions, data movement
Performance limiters

Profiling is the process of measuring the performance of a program in a way that reveals where resources (e.g., time, memory) are being spent during execution. Profiling is important in benchmarking for the following reasons:

\begin{itemize}
    \item Profiling helps explain why a particular method or implementation is faster than another.
    \item Profiling helps support fair and reproducible benchmarking.
    \item Profiling can distinguish between computation and overheads.
    \item In a heterogeneous system, profiling can identify which components (e.g., CPU or GPU, CUDA cores vs. tensor cores) are being used by different parts of the application.
    \item Profiling can identify which specific library kernels are being used by different parts of the application.
\end{itemize}

Some profiling tools that are useful for analysis of deep learning applications are listed in Table~\ref{tab:dl_profiling_tools}.

\begin{table*}[htbp]
\centering
\caption{Tools for Profiling Deep Learning Codes}
\label{tab:dl_profiling_tools}
\begin{tabular}{|p{3cm}|l|p{3cm}|p{8cm}|}
\hline
\textbf{Tool} & \textbf{\makecell[l]{Vendor \\or Maintainer}} & \textbf{Level} & \textbf{Key Features} \\ 
\hline
\hline
\textnormal{Nsight Systems} & NVIDIA & System-level & Timeline visualization, CPU-GPU interactions, kernel launch overheads, multi-process analysis. \\ \hline
\textnormal{Nsight Compute} & NVIDIA & Kernel-level & Low-level GPU kernel performance metrics, Tensor Core utilization, roofline analysis. \\ \hline
\textnormal{nvprof} (deprecated) & NVIDIA & GPU-level & Command-line profiler for CUDA applications, replaced by Nsight tools. \\ \hline
\textnormal{TensorBoard Profiler} & Google & Framework-level & Trace visualization, op-level profiling, device utilization, bottleneck analysis. \\ \hline
\textnormal{PyTorch Profiler} & Meta & Framework-level & Operator-level timing, GPU utilization, integration with TensorBoard, memory usage. \\ \hline
\textnormal{torch.utils.bottleneck} & Meta & Framework-level & Quick bottleneck diagnostics, autograd profiler + Python profiler. \\ \hline
\textnormal{Perfetto} & \makecell[l]{Google \\(Open Source)} & System-level & High-resolution trace visualization, works with PyTorch Profiler exports. \\ \hline
\textnormal{VTune Profiler} & Intel & CPU / System-level & Hotspot analysis, vectorization, threading, CPU performance bottlenecks. \\ \hline
\textnormal{rocprof / rocm-smi} & AMD & GPU-level & Profiling and monitoring for AMD GPUs, kernel execution metrics. \\ \hline
\textnormal{HPCToolkit} & Rice University & System-level (CPU+GPU) & Hierarchical profiling, attribution of time to calling context, supports CUDA/HIP. \\ \hline
\textnormal{TAU} & \makecell[l]{University of\\Oregon} & System-level & Multi-level performance analysis, MPI integration, supports GPUs and CPUs. \\ \hline
\textnormal{NCCL Profiler} & NVIDIA & Communication-level & Profiling collective communication (NCCL), timeline visualization of all-reduce, broadcast, etc. \\ \hline
\textnormal{XLA Profiler} & Google & Compiler-level (XLA) & Profiling of XLA-compiled ops and execution times, useful for TPU and GPU backends. \\ \hline
\textnormal{Triton Profiler} & OpenAI & Kernel-level & Reports kernel execution time, register usage, occupancy for custom kernels. \\ \hline
\textnormal{PAPI} & \makecell[l]{University of \\Tennessee} & Hardware counter interface & Low-level access to CPU and GPU performance counters, used in custom instrumentation or integrated with other profilers. \\ \hline

\end{tabular}
\end{table*}
