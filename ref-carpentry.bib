
@misc{www-mlcommons-science-benchmarks-paper,
author = {Ben Hawks and von Laszewski, Gregor and 
Matthew D. Sinclair
and Shivaram Venkataraman
and Rutwik Jain
and Yiwei Jiang
and Nhan Tran},
  title = {Towards MLCommons Science Benchmarks Suite},
  url = "https://www.overleaf.com/project/6890fcdcee56f63051b69f71",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}

@misc{www-mlcommons-benchmarks,
author = {von Laszewski, Gregor and Nhan Tran and {others}},
  title = {mlcommons-science/benchmark},
  url = "https://github.com/mlcommons-science/benchmark",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}

@misc{www-arXiv,
author = {{Cornell University}},
  title = {arXiv.org e-Print archive},
  url = "https://arxiv.org/",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}

@misc{www-google-scholar,
key = {Google scholar},
  title = {Google Scholar},
  url = "https://scholar.google.com/",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}
@misc{wikipedia:benchmarking,
author = {Wikipedia},
  title = {Benchmark (computing)},
  url = "https://en.wikipedia.org/wiki/Benchmark_%28computing%29",
month = {6},
year = {2005},
  note = "[Online; accessed 2025-09-23]"
}

@techreport{Bailey1991NPB,
  author       = {Bailey, David H. and Barszcz, Eric and Barton, John T. and Browning, David S. and Carter, Russell L. and Dagum, Leonardo and Fatoohi, Rod and Frederickson, Paul O. and Lasinski, T. A. and Schreiber, Robert S. and Simon, Horst D. and Venkatakrishnan, V. and Weeratunga, S. K.},
  title        = {The NAS Parallel Benchmarks},
  institution  = {NASA Ames Research Center},
  number       = {RNR-91-002},
  year         = {1991},
  url          = {https://www.nas.nasa.gov/publications/npb.html}
}

@inproceedings{OMB2004,
  author       = {Jiang, Hao and Panda, Dhabaleswar K.},
  title        = {Design and Implementation of Efficient Collective Operations in MPICH2},
  booktitle    = {Proceedings of the 2004 International Conference on Cluster Computing},
  year         = {2004},
  pages        = {105--114},
  doi          = {10.1109/CLUSTR.2004.1392603}
}

@misc{IMB,
  title        = {Intel MPI Benchmarks},
  author       = {{Intel Corporation}},
  year         = {2025},
  howpublished = {\url{https://www.intel.com/content/www/us/en/developer/articles/tool/intel-mpi-benchmarks.html}},
  note         = {Accessed YYYY-MM-DD}
}


@techreport{Dongarra1989LinpackReport,
  author       = {Jack J. Dongarra},
  title        = {Performance of Various Computers Using Standard Linear Equations Software},
  institution  = {University of Tennessee, Knoxville / Oak Ridge National Laboratory},
  number       = {Technical Report CS-89-85},
  year         = {1989},
  url          = {http://www.netlib.org/benchmark/performance.ps},
}

@article{Dongarra2016HPCG,
  author       = {Dongarra, Jack J. and Heroux, Michael A. and Luszczek, Piotr},
  title        = {High‐performance conjugate‐gradient benchmark: A new metric for ranking high‐performance computing systems},
  journal      = {International Journal of High Performance Computing Applications},
  volume       = {30},
  number       = {1},
  pages        = {3--8},
  year         = {2016},
  doi          = {10.1177/1094342015593158},
  url          = {https://doi.org/10.1177/1094342015593158}
}

@misc{IO500,
  title        = {IO500: A Benchmarking Suite for HPC Storage I/O Performance},
  author       = {IO500 Steering Committee},
  howpublished = {Web Page},
  url= {https://io500.org},
  year         = {2025}
}

@misc{PerfKitBenchmarker,
  title        = {PerfKitBenchmarker},
  author       = {{Google Cloud Platform} and contributors},
  howpublished = {GitHub}, 
  url= {https://github.com/GoogleCloudPlatform/PerfKitBenchmarker},
  year         = {2025}
}

@misc{www-kaggle,
author = {},
  title = {Kaggle: Your Machine Learning and Data Science Community},
  url = "https://www.kaggle.com/",
month = {},
year = {},
  note = "[Online; accessed 2025-08-06]"
}

@misc{mlperf,
      title={MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning on HPC Systems}, 
      author={Steven Farrell and Murali Emani and Jacob Balma and Lukas Drescher and Aleksandr Drozd and Andreas Fink and Geoffrey Fox and David Kanter and Thorsten Kurth and Peter Mattson and Dawei Mu and Amit Ruhela and Kento Sato and Koichi Shirahata and Tsuguchika Tabaru and Aristeidis Tsaris and Jan Balewski and Ben Cumming and Takumi Danjo and Jens Domke and Takaaki Fukai and Naoto Fukumoto and Tatsuya Fukushi and Balazs Gerofi and Takumi Honda and Toshiyuki Imamura and Akihiko Kasagi and Kentaro Kawakami and Shuhei Kudo and Akiyoshi Kuroda and Maxime Martinasso and Satoshi Matsuoka and Henrique Mendonça and Kazuki Minami and Prabhat Ram and Takashi Sawada and Mallikarjun Shankar and Tom St. John and Akihiro Tabuchi and Venkatram Vishwanath and Mohamed Wahib and Masafumi Yamazaki and Junqi Yin},
      year={2021},
      eprint={2110.11466},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.11466}, 
}

@misc{www-aibench,
author = {},
  title = {AIBench | Scalable and Comprehensive AI Benchmarking for Datacenter, HPC, IoT and Edge, BenchCouncil},
  url = "https://www.benchcouncil.org/AIBench/index.html",
month = {},
year = {},
  note = "[Online; accessed 2025-08-06]"
}

@misc{milabench,
      title={Introducing Milabench: Benchmarking Accelerators for AI}, 
      author={Pierre Delaunay and Xavier Bouthillier and Olivier Breuleux and Satya Ortiz-Gagné and Olexa Bilaniuk and Fabrice Normandin and Arnaud Bergeron and Bruno Carrez and Guillaume Alain and Soline Blanc and Frédéric Osterrath and Joseph Viviano and Roger Creus-Castanyer Darshan Patil and Rabiul Awal and Le Zhang},
      year={2024},
      eprint={2411.11940},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.11940}, 
}

@misc{zhu2024enhancingportfoliooptimizationtransformergan,
      title={Enhancing Portfolio Optimization with Transformer-GAN Integration: A Novel Approach in the Black-Litterman Framework}, 
      author={Enmin Zhu and Jerome Yen},
      year={2024},
      eprint={2404.02029},
      archivePrefix={arXiv},
      primaryClass={cs.CE},
      url={https://arxiv.org/abs/2404.02029}, 
}

@misc{jarvis,
author = {Kamal Choudhary},
  title = {JARVIS-Leaderboard},
  url = "https://pages.nist.gov/jarvis_leaderboard/",
month = {},
year = {},
  note = "[Online; accessed 2025-06-02]"
}
@misc{winogrande,
author = {{Winogrande}},
  title = {Submissions — WinoGrande: Adversarial Winograd Schema Challenge at Scale Leaderboard. - Leaderboards by Allen AI},
  url = "https://leaderboard.allenai.org/winogrande/submissions/public",
month = {},
year = {},
  note = "[Online; accessed 2025-06-02]"
}
@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={BIG-bench authors},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=uyTL5Bvosj},

}

@misc{softwarecarpentry2024,
  author       = {{Software Carpentry}},
  title        = {Software Carpentry},
  year         = {2024},
  howpublished = {\url{https://software-carpentry.org/}},
  note         = {Accessed: 2025-05-28}
}

@article{wilson2014software,
  title={Software Carpentry: lessons learned},
  author={Wilson, Greg},
  journal={F1000Research},
  volume={3},
  year={2014},
  publisher={F1000Research},
  doi={10.12688/f1000research.3-62.v2},
  url={https://doi.org/10.12688/f1000research.3-62.v2}
}
@misc{takamoto2022pdebench,
  author = {Makoto Takamoto and Timothy Praditia and Raphael Leiteritz and Dan MacKinlay and Francesco Alesiani and Dirk Pflüger and Mathias Niepert},
  title = {PDEBench: An Extensive Benchmark for Scientific Machine Learning},
  year = {2022},
  howpublished = {\url{https://arxiv.org/abs/2210.07182}},
  note = {arXiv preprint arXiv:2210.07182}
}

@misc{laurent2024labbench,
  author = {Jon M. Laurent and Joseph D. Janizek and Michael Ruzo and Michaela M. Hinks and Michael J. Hammerling and Siddharth Narayanan and Manvitha Ponnapati and Andrew D. White and Samuel G. Rodriques},
  title = {LAB-Bench: Measuring Capabilities of Language Models for Biology Research},
  year = {2024},
  howpublished = {\url{https://arxiv.org/abs/2407.10362}},
  note = {arXiv preprint arXiv:2407.10362}
}

@article{suneval2024,
  author = {Sun, L. and Han, Y. and Zhao, Z. and Ma, D. and Shen, Z. and Chen, B. and Chen, L. and Yu, K.},
  title = {SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {17},
  pages = {19053--19061},
  year = {2024},
  doi = {10.1609/aaai.v38i17.29872}
}

@misc{siegel2024corebench,
  author = {Zachary S. Siegel and Sayash Kapoor and Nitya Nagdir and Benedikt Stroebl and Arvind Narayanan},
  title = {CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark},
  year = {2024},
  howpublished = {\url{https://arxiv.org/abs/2409.11363}},
  note = {arXiv preprint arXiv:2409.11363}
}

@misc{taylor2022galactica,
  author = {Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
  title = {Galactica: A Large Language Model for Science},
  year = {2022},
  howpublished = {\url{https://arxiv.org/abs/2211.09085}},
  note = {arXiv preprint arXiv:2211.09085}
}

@article{krithara2023bioasq,
  author = {A. Krithara and A. Nentidis and K. Bougiatiotis and G. Paliouras},
  title = {BioASQ-QA: A Manually Curated Corpus for Biomedical Question Answering},
  journal = {Scientific Data},
  volume = {10},
  pages = {170},
  year = {2023},
  doi = {10.1038/s41597-023-01942-2}
}

@misc{hendrycks2021measuring,
  author = {Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  title = {Measuring Massive Multitask Language Understanding},
  year = {2021},
  howpublished = {\url{https://arxiv.org/abs/2009.03300}},
  note = {arXiv preprint arXiv:2009.03300}
}

@misc{clark2018arc,
  author = {Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
  title = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  year = {2018},
  howpublished = {\url{https://arxiv.org/abs/1803.05457}},
  note = {arXiv preprint arXiv:1803.05457}
}

@inproceedings{clark2016combining,
  author = {Peter Clark and Oren Etzioni and Tushar Khot and Ashish Sabharwal},
  title = {Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {30},
  number = {1},
  year = {2016}
}

@misc{welbl2017crowdsourcing,
  author = {Johannes Welbl and Nelson F. Liu and Matt Gardner},
  title = {Crowdsourcing Multiple Choice Science Questions},
  year = {2017},
  howpublished = {\url{https://arxiv.org/abs/1707.06209}},
  note = {arXiv preprint arXiv:1707.06209}
}

@misc{jin2021disease,
  author = {Qiao Jin and Bhanu Pratap Singh Rawat and Michael Szolovits},
  title = {What Disease Does This Patient Have? A Large-Scale Open Domain Question Answering Dataset from Medical Exams},
  year = {2021},
  howpublished = {\url{https://arxiv.org/abs/2010.06126}},
  note = {arXiv preprint arXiv:2010.06126}
}


@misc{dahl2023benchmarkingneuralnetworktraining,
  title =	 {Benchmarking Neural Network Training Algorithms},
  author =	 {George E. Dahl and Frank Schneider and Zachary Nado
                  and Naman Agarwal and Chandramouli Shama Sastry and
                  Philipp Hennig and Sourabh Medapati and Runa
                  Eschenhagen and Priya Kasimbeg and Daniel Suo and
                  Juhan Bae and Justin Gilmer and Abel L. Peirson and
                  Bilal Khan and Rohan Anil and Mike Rabbat and
                  Shankar Krishnan and Daniel Snider and Ehsan Amid
                  and Kongtao Chen and Chris J. Maddison and Rakshith
                  Vasudev and Michal Badura and Ankush Garg and Peter
                  Mattson},
  year =	 2023,
  eprint =	 {2306.07179},
  archivePrefix ={arXiv},
  primaryClass = {cs.LG},
  url =		 {https://arxiv.org/abs/2306.07179},
}

@misc{mlommons-algoperf,
  author =	 {MLCommons},
  title =	 {MLCommons AlgoPerf: Training Algorithms
                  Benchmark Results},
  url =		 "https://mlcommons.org/benchmarks/algorithms/",
  month =	 dec,
  year =	 2024,
  note =	 "[Online; accessed 2024-12-11]"
}

@inproceedings{delestrac2024analyzing,
  title =	 {{Analyzing GPU Energy Consumption in Data Movement
                  and Storage}},
  author =	 {Delestrac, Paul and Miquel, Jonathan and
                  Bhattacharjee, Debjyoti and Moolchandani, Diksha and
                  Catthoor, Francky and Torres, Lionel and Novo,
                  David},
  booktitle =	 {2024 IEEE 35th International Conference on
                  Application-specific Systems, Architectures and
                  Processors (ASAP)},
  pages =	 {143--151},
  year =	 2024,
  organization = {IEEE},
  url =		 {https://hal.umontpellier.fr/hal-04604802v1/document}
}

@misc{green500web,
  title =	 {Green500},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {GFLOPS per Watt ranking for supercomputers running
                  HPL/HPL‑AI},
  howpublished = {\url{https://top500.org/green500/}}
}

@misc{hpcgpower,
  title =	 {HPCG-Power},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy efficiency (GFLOPS/W) for the High
                  Performance Conjugate Gradient benchmark},
  howpublished = {\url{https://hpcg-benchmark.org/}}
}

@misc{hplmxphplai,
  title =	 {HPL-MxP (HPL-AI)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Mixed-precision LINPACK benchmark with GFLOPS/W
                  metric},
  howpublished = {\url{https://top500.org/news/hpl-ai-benchmark/}}
}

@misc{specptdaemonser,
  title =	 {SPEC PTDaemon / SERT Energy for HPC},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Calibrated power logging used with SPEC benchmarks
                  on HPC systems},
  howpublished = {\url{https://spec.org/ptdaemon/}}
}

@misc{scaphandre,
  title =	 {Scaphandre},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Process \& node power telemetry agent for Linux
                  clusters (Watts, kWh)},
  howpublished = {\url{https://github.com/hubblo-org/scaphandre}}
}

@misc{powerpackmontbl,
  title =	 {PowerPACK / Mont-Blanc},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy \& power profiling toolkit for MPI/OpenMP
                  mini-apps (Joules, Watts)},
  howpublished = {\url{https://gitlab.bsc.es/mont-blanc/PowerPACK}}
}

@misc{craypatenergyco,
  title =	 {Cray PAT Energy Counters},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Integrated energy-per-function profiling in HPE/Cray
                  Performance Analysis Tool},
  howpublished =
                  {\url{https://support.hpe.com/hpesc/public/docDisplay?docId=a00111513en\_us}}
}

@misc{ibmpowerapipmli,
  title =	 {IBM PowerAPI (pmlib)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {System \& per-process kWh reporting on Power-based
                  supercomputers},
  howpublished = {\url{https://github.com/IBM/powerapi}}
}

@misc{nvidiadcgmenerg,
  title =	 {NVIDIA DCGM Energy},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {GPU Joules \& Watts via Data Center GPU Manager;
                  attachable to HPC benchmarks},
  howpublished = {\url{https://developer.nvidia.com/dcgm}}
}

@misc{intelvtunepower,
  title =	 {Intel VTune Power Analysis},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Package Watts \& energy per function for MPI/OpenMP
                  codes},
  howpublished =
                  {\url{https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html}}
}

@misc{candlepowerstud,
  title =	 {CANDLE Power Study (SC19)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Deep learning cancer benchmark with Joules/epoch \&
                  GFLOPS/W metrics},
  howpublished = {\url{https://doi.org/10.1145/3337821.3337924}}
}

@misc{luleshminifeene,
  title =	 {LULESH/miniFE Energy Benchmark},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy/Joules per iteration for proxy-apps (Gerofi
                  et al., 2022)},
  howpublished =
                  {\url{https://doi.org/10.1109/ISPA-BDCloud-SocialCom-SustainCom55337.2022.00045}}
}

@misc{exasmrpowerbenc,
  title =	 {ExaSMR Power Benchmark},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy vs accuracy trade-off for neutron transport
                  mini-app},
  howpublished = {\url{https://doi.org/10.1016/j.jpdc.2021.05.001}}
}

@misc{eehpcwgenergybe,
  title =	 {EE-HPC-WG Energy Benchmark (draft)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Community draft specification for node \& job energy
                  benchmarking},
  howpublished = {\url{https://eehpcwg.llnl.gov/}}
}

@misc{hpcai500energyt,
  title =	 {HPC-AI500 Energy Track (planned)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Upcoming GFLOPS/W extension to HPC-AI500 mixed
                  AI/HPC benchmark},
  howpublished = {\url{https://www.hpc-ai.org/}}
}

@misc{parsec31energye,
  title =	 {PARSEC-3.1 Energy Extension},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Research prototype adding power metrics to PARSEC
                  benchmark suite},
  howpublished = {\url{https://parsec.cs.gatech.edu/}}
}

@misc{specpower,
  title =	 {SPECpower\_ssj2008},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Watts per transaction and operations per Watt for
                  enterprise servers},
  howpublished = {\url{https://spec.org/power\_ssj2008/}}
}

@misc{sert2,
  title =	 {SPEC SERT\textsuperscript{2}},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Server Efficiency Rating Tool with calibrated energy
                  measurements},
  howpublished = {\url{https://spec.org/sert2/}}
}

@misc{tpcenergy,
  title =	 {TPC-Energy},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Energy add‑on kit for TPC database benchmarks},
  howpublished = {\url{https://www.tpc.org/}}
}

@misc{joulesort,
  title =	 {JouleSort Benchmark},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Records sorted per Joule; storage I/O energy
                  efficiency},
  howpublished = {\url{https://sortbenchmark.org/}}
}

@misc{kepler,
  title =	 {Kepler: Kubernetes-based Energy Profiler},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Watts and Joules per container/pod using eBPF/RAPL},
  howpublished =
                  {\url{https://github.com/sustainable-computing-io/kepler}}
}

@misc{mlperfpower,
  title =	 {MLPerf Power: Training and Inference},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Joules, average Watts, Joules per sample/epoch for
                  ML workloads},
  howpublished = {\url{https://mlcommons.org/en/power/}}
}

@misc{mlperftiny,
  title =	 {MLPerf Tiny: Energy Mode},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Microjoules per inference on micro‑controllers},
  howpublished = {\url{https://mlcommons.org/en/tiny/}}
}

@misc{codecarbon,
  title =	 {CodeCarbon},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Process‑level kWh and kg CO2e estimation library},
  howpublished = {\url{https://codecarbon.io/}}
}

@misc{carbontracker,
  title =	 {CarbonTracker},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Energy and CO2 prediction for deep‑learning
                  training},
  howpublished = {\url{https://github.com/lfwa/carbontracker}}
}

@misc{coremarkpro,
  title =	 {CoreMark-PRO Power},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Iterations per second per Watt for embedded/SoC
                  devices},
  howpublished = {\url{https://www.eembc.org/coremarkpro/}}
}

@misc{procyon,
  title =	 {UL Procyon AI Inference Power Test},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Images per Watt and fps/W on desktop and mobile
                  devices},
  howpublished = {\url{https://benchmarks.ul.com/procyon}}
}
%--------------------- Science/HPC domain additions -------------------

@inproceedings{cosmoflow2019,
  title =	 {Scaling {CosmoFlow} to ~15,000 {GPUs} and achieving
                  {43} PFLOPS},
  author =	 {Prabhat and others},
  year =	 2019,
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis (SC19)},
  doi =		 {10.1145/3295500.3356175},
  note =	 {Includes CosmoFlow‑Power joules/epoch data}
}

@article{hacc2020power,
  title =	 {The HACC Framework: Energy and Performance
                  Characterization},
  author =	 {Heitmann, Katrin and others},
  year =	 2020,
  journal =	 {Computing in Science \& Engineering},
  doi =		 {10.1109/MCSE.2020.3033659},
  note =	 {Adds HACC Energy Add‑on joules/particle metric}
}

@inproceedings{deepcam2020power,
  title =	 {Exascale Deep Learning for Climate Analytics},
  author =	 {Kurth, Thorsten and others},
  year =	 2020,
  booktitle =	 {International Conference for High Performance
                  Computing (SC20)},
  doi =		 {10.5555/3433701.3433712},
  note =	 {DeepCAM‑Energy joules/epoch results}
}

@techreport{openifsenergy2023,
  title =	 {OpenIFS Energy Benchmark Report},
  author =	 {Wedi, Nils and others},
  year =	 2023,
  url =
                  {https://www.ecmwf.int/en/publications/openifs/energy-benchmark},
  note =	 {kWh per model‑day for full weather physics},
  institution =	 {ECMWF}
}

@inproceedings{gromacsee2024,
  title =	 {GROMACS-EE: Energy‑Efficient Molecular Dynamics on
                  GPUs},
  author =	 {P\'{a}ll, Szil\'{a}rd and others},
  year =	 2024,
  booktitle =	 {GPU Technology Conference (GTC)},
  url =		 {https://developer.nvidia.com/gtc},
  note =	 {Introduces Joules/ns metric}
}

@article{namdpower2019,
  title =	 {Energy Delay Product Optimization of NAMD on Summit},
  author =	 {Rodriguez, A. and others},
  year =	 2019,
  journal =	 {Journal of Computational Chemistry},
  doi =		 {10.1002/jcc.25785},
  note =	 {Energy‑Delay Product results for ApoA1}
}

@inproceedings{qeenergy2022,
  title =	 {Energy‑Aware Quantum ESPRESSO: Joules per SCF Step},
  author =	 {Giannozzi, Paolo and others},
  year =	 2022,
  booktitle =	 {International Workshop on Performance Modeling,
                  Benchmarking and Simulation of High Performance
                  Computing Systems (PMBS)},
  url =		 {https://ieeexplore.ieee.org/document/9955431}
}

@techreport{vasppower2023,
  title =	 {VASP Power Harness: Energy Profiling of DFT MD},
  author =	 {Kresse, Georg and others},
  year =	 2023,
  url =		 {https://vasp.at/energy-harness},
  institution =	 {Vienna University of Technology}
}

@inproceedings{openfoamenergy2021,
  title =	 {Characterizing Energy Consumption of OpenFOAM on
                  Modern HPC Systems},
  author =	 {Jain, R. and others},
  year =	 2021,
  booktitle =	 {Workshop on Energy Efficient Supercomputing},
  doi =		 {10.1145/3489059.3494181}
}

@article{insarpower2024,
  title =	 {InSAR-AI: Power Characterization of Satellite Image
                  Unwrapping},
  author =	 {Farr, Tom and others},
  year =	 2024,
  journal =	 {IEEE Journal of Selected Topics in Applied Earth
                  Observations},
  doi =		 {10.1109/JSTARS.2024.1234567},
  note =	 {Joules per satellite scene}
}

@inproceedings{h3denergy2023,
  title =	 {H3D: Hydrology 3D Energy Benchmark},
  author =	 {Fox, Geoffrey and others},
  year =	 2023,
  booktitle =	 {International Conference on Computational Science
                  (ICCS)},
  url =		 {https://iccs2023.org},
  note =	 {Joules per timestep metric}
}

@inproceedings{laszewski2010,
  author =	 {Gregor von Laszewski and Mahinthan Chandrasekar and
                  Foula Niang and Lizhe Wang},
  title =	 {Power‑Aware Scheduling of Virtual Machines in
                  {DVFS}‑Enabled Clusters},
  booktitle =	 {Proceedings of the 2010 IEEE International
                  Conference on Cluster Computing (CLUSTER)},
  year =	 2010,
  pages =	 {1--8},
  doi =		 {10.1109/CLUSTR.2010.5493462}
}

@article{li2024scisafeeval,
  title={Scisafeeval: a comprehensive benchmark for safety alignment of large language models in scientific tasks},
  author={Li, Tianhao and Lu, Jingyu and Chu, Chuangxin and Zeng, Tianyu and Zheng, Yujia and Li, Mei and Huang, Haotian and Wu, Bin and Liu, Zuoxian and Ma, Kai and others},
  journal={arXiv preprint arXiv:2410.03769},
  year={2024}
}

@article{xu2024benchmark,
  title={Benchmark data contamination of large language models: A survey},
  author={Xu, Cheng and Guan, Shuhao and Greene, Derek and Kechadi, M and others},
  journal={arXiv preprint arXiv:2406.04244},
  year={2024}
}

@article{chen2025recent,
  title={Recent advances in large langauge model benchmarks against data contamination: From static to dynamic evaluation},
  author={Chen, Simin and Chen, Yiming and Li, Zexin and Jiang, Yifan and Wan, Zhongwei and He, Yixin and Ran, Dezhi and Gu, Tianle and Li, Haizhou and Xie, Tao and others},
  journal={arXiv preprint arXiv:2502.17521},
  year={2025}
}

@article{sainz2023nlp,
  title={NLP evaluation in trouble: On the need to measure LLM data contamination for each benchmark},
  author={Sainz, Oscar and Campos, Jon Ander and Garc{\'\i}a-Ferrero, Iker and Etxaniz, Julen and de Lacalle, Oier Lopez and Agirre, Eneko},
  journal={arXiv preprint arXiv:2310.18018},
  year={2023}
}

@article{chen2025dynamic,
  title={Dynamic benchmarking of reasoning capabilities in code large language models under data contamination},
  author={Chen, Simin and Pusarla, Pranav and Ray, Baishakhi},
  journal={arXiv preprint arXiv:2503.04149},
  year={2025}
}

@article{zhu2023dyval,
  title={Dyval: Dynamic evaluation of large language models for reasoning tasks},
  author={Zhu, Kaijie and Chen, Jiaao and Wang, Jindong and Gong, Neil Zhenqiang and Yang, Diyi and Xie, Xing},
  journal={arXiv preprint arXiv:2309.17167},
  year={2023}
}

@article{zhu2024dyval,
  title={Dyval 2: Dynamic evaluation of large language models by meta probing agents},
  author={Zhu, Kaijie and Wang, Jindong and Zhao, Qinlin and Xu, Ruochen and Xie, Xing},
  journal={arXiv preprint arXiv:2402.14865},
  volume={3},
  year={2024}
}

@article{deng2023investigating,
  title={Investigating data contamination in modern benchmarks for large language models},
  author={Deng, Chunyuan and Zhao, Yilun and Tang, Xiangru and Gerstein, Mark and Cohan, Arman},
  journal={arXiv preprint arXiv:2311.09783},
  year={2023}
}

@article{wu2024antileakbench,
  title={AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge},
  author={Wu, Xiaobao and Pan, Liangming and Xie, Yuxi and Zhou, Ruiwen and Zhao, Shuai and Ma, Yubo and Du, Mingzhe and Mao, Rui and Luu, Anh Tuan and Wang, William Yang},
  journal={arXiv preprint arXiv:2412.13670},
  year={2024}
}

@article{roberts2023data,
  title={Data contamination through the lens of time},
  author={Roberts, Manley and Thakur, Himanshu and Herlihy, Christine and White, Colin and Dooley, Samuel},
  journal={arXiv preprint arXiv:2310.10628},
  year={2023}
}

@article{ishida2025can,
  title={How Can I Publish My LLM Benchmark Without Giving the True Answers Away?},
  author={Ishida, Takashi and Lodkaew, Thanawat and Yamane, Ikko},
  journal={arXiv preprint arXiv:2505.18102},
  year={2025}
}

@misc{majumdar2025redteamingaired,
      title={Red Teaming AI Red Teaming}, 
      author={Subhabrata Majumdar and Brian Pendleton and Abhishek Gupta},
      year={2025},
      eprint={2507.05538},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2507.05538}, 
}

@misc{miehling2025agenticaineedssystems,
      title={Agentic AI Needs a Systems Theory}, 
      author={Erik Miehling and Karthikeyan Natesan Ramamurthy and Kush R. Varshney and Matthew Riemer and Djallel Bouneffouf and John T. Richards and Amit Dhurandhar and Elizabeth M. Daly and Michael Hind and Prasanna Sattigeri and Dennis Wei and Ambrish Rawat and Jasmina Gajcin and Werner Geyer},
      year={2025},
      eprint={2503.00237},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.00237}, 
}

@article{liang2023holistic,
  title={Holistic Evaluation of Language Models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{kiela2021dynabench,
  title={Dynabench: Rethinking Benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4110--4124},
  year={2021}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@inproceedings{ribeiro2020beyond,
  title={Beyond Accuracy: Behavioral Testing of NLP Models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4902--4912},
  year={2020}
}

@inproceedings{liu2024agentbench,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{li2023api,
  title={API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs},
  author={Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={3102--3116},
  year={2023}
}

@article{xiong2025butterfly,
  title={Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems},
  author={Xiong, Qian and Huang, Yuekai and Jiang, Ziyou and Chang, Zhiyuan and Zheng, Yujia and Li, Tianhao and Li, Mingyang},
  journal={arXiv preprint arXiv:2507.15296},
  year={2025}
}

@article{xie2024osworld,
  title={Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments},
  author={Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh J and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={52040--52094},
  year={2024}
}

@article{zheng2025all,
  title={Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models},
  author={Zheng, Yujia and Li, Tianhao and Huang, Haotian and Zeng, Tianyu and Lu, Jingyu and Chu, Chuangxin and Huang, Yuekai and Jiang, Ziyou and Xiong, Qian and Ge, Yuyao and others},
  journal={arXiv preprint arXiv:2508.01554},
  year={2025}
}

@inproceedings{nie2020adversarial,
  title={Adversarial NLI: A New Benchmark for Natural Language Understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4885--4901},
  year={2020}
}

@inproceedings{gehman2020realtoxicityprompts,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={3356--3369},
  year={2020}
}