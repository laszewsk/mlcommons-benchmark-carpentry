\section{Profiling and performance analysis}
\label{sec:prof}

Profiling is the process of measuring a program's performance to reveal where resources (e.g., time and memory) are spent during execution. Profiling is important in AI benchmarking for the following reasons:

\begin{itemize}
    \item Profiling helps explain why a particular method or implementation is faster than another.
    \item Profiling helps support fair and reproducible benchmarking.
    \item Profiling can distinguish between computation and overheads.
    \item In a heterogeneous system, profiling can identify which components (e.g., CPU or GPU, CUDA cores vs. tensor cores) are being used by different parts of the application.
    \item Profiling can identify which specific library kernels are being used by different parts of the application.
\end{itemize}

Some profiling tools that are useful for analysis of deep learning applications are listed in Table~\ref{tab:dl_profiling_tools}.

\begin{table*}[htbp]
\centering
\caption{Summary of Example Profiling Tools Useful for Deep Learning and AI Workloads}
\label{tab:merged_profiling_tools}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{|p{0.2\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|p{0.4\textwidth}|}
\hline
\rowcolor{blue!20} \textbf{Tool / Category} & \textbf{Vendor / Maintainer} & \textbf{Level / Primary Use Case} & \textbf{Key Features and Capabilities} \\ 
\hline
\hline
\rowcolor{gray!30} \multicolumn{4}{|l|}{\textbf{Framework Profilers}} \\ \hline
PyTorch Profiler~\cite{TensorFlow_System} & Meta & Framework-level & Records CPU/GPU activities, memory usage, and operator timings; integrates with TensorBoard and Perfetto; useful for training optimization and layer timing. \\ \hline
TensorBoard / TensorFlow Profiler~\cite{TensorFlow_System} & Google & Framework-level & Visualizes input pipelines, GPU kernels, and op-level timings; includes memory and device utilization tracing; supports bottleneck analysis. \\ \hline
torch.utils.bottleneck~\cite{PyTorch_System} & Meta & Framework-level & Combines autograd and Python profilers for quick bottleneck diagnostics. \\ \hline
JAX Profiler~\cite{JAX_Profiler} & Google & Framework-level & Works with TensorBoard to trace XLA compilation, HLO graphs, and TPU/GPU runtime performance. \\ \hline
NVIDIA DLProf~\cite{NVIDIA_DLProf} & NVIDIA & Framework-level (GPU-focused) & High-level view of deep learning layers and operations; integrates with TensorBoard DLProf plugin. \\ \hline
\rowcolor{gray!30} \multicolumn{4}{|l|}{\textbf{Hardware / System Profilers}} \\ \hline
Nsight Systems~\cite{NVIDIA_NsightSys_Doc} & NVIDIA & System-level & Timeline visualization of CPUâ€“GPU interactions, kernel launch overheads, multi-process analysis, and NCCL tracing. \\ \hline
Nsight Compute~\cite{NVIDIA_NsightComp_Doc} & NVIDIA & Kernel-level & Detailed GPU kernel performance metrics: memory throughput, Tensor Core utilization, occupancy, and roofline analysis. \\ \hline
nvprof (deprecated)~\cite{NVIDIA:CUDA:ProfilerGuide} & NVIDIA & GPU-level & Legacy command-line CUDA profiler, replaced by Nsight tools. \\ \hline
VTune Profiler~\cite{Intel_VTune_Doc} & Intel & CPU/System-level & Hotspot analysis, vectorization, threading efficiency, and CPU performance bottlenecks. \\ \hline
omnitrace / rocprof / rocm-smi~\cite{AMD_ROCM_Doc} & AMD & GPU-level & Profiling and monitoring for AMD GPUs: kernel execution metrics, power, and temperature. \\ \hline
HPCToolkit~\cite{HPCToolkit_Paper} & Rice University & System-level (CPU+GPU) & Hierarchical performance profiling, time attribution to calling context, supports CUDA and HIP. \\ \hline
TAU~\cite{TAU_Paper} & University of Oregon & System-level (CPU+GPU+MPI) & Multi-level performance analysis, MPI integration, supports heterogeneous systems. \\ \hline
Perfetto~\cite{Perfetto_Google} & Google (Open Source) & System-level & High-resolution trace visualization, interoperable with PyTorch/TensorFlow profiler exports. \\ \hline
PAPI~\cite{PAPI_Paper} & University of Tennessee & Hardware counter interface & Provides access to CPU/GPU performance counters for integration with other profiling tools or custom instrumentation. \\ \hline
\rowcolor{gray!30} \multicolumn{4}{|l|}{\textbf{Compiler / Graph Profilers}} \\ \hline
XLA Profiler~\cite{XLA_Paper} & Google & Compiler-level (XLA) & Profiles XLA-compiled operations and execution times; supports JAX/TF and TPU/GPU workloads. \\ \hline
TorchDynamo / TorchInductor Debug Tools~\cite{TorchDynamo_TorchInductor} & Meta & Compiler-level (PyTorch 2.x) & Analyzes graph fusion, compiler optimizations, and operator performance of compiled PyTorch models. \\ \hline
Triton Profiler~\cite{Triton_Paper} & OpenAI & Kernel-level (Custom Kernels) & Reports kernel execution time, register usage, and occupancy for custom Triton GPU kernels. \\ \hline
\rowcolor{gray!30} \multicolumn{4}{|l|}{\textbf{Communication / Distributed Profilers}} \\ \hline
NCCL Profiler~\cite{NVIDIA_NCCL_Doc} & NVIDIA & Communication-level & Profiles NCCL collective communication operations (e.g., all-reduce, broadcast); timeline visualization of multi-GPU communication. \\ \hline
AWS SageMaker Debugger / Azure Profiler~\cite{AWS_SageMaker_Debugger,Azure_Profiler} & AWS / Microsoft & Cloud-level & Distributed GPU/CPU monitoring, training metric collection, and profiling at cloud scale. \\ \hline
Weights \& Biases, Comet, MLflow~\cite{Weights_Biases,Comet_ML,MLflow} & Multiple Vendors & Experiment / Cloud-level & Logs performance traces, GPU utilization, integrates with PyTorch and TensorFlow profilers for real-time monitoring. \\ \hline
\rowcolor{gray!30} \multicolumn{4}{|l|}{\textbf{System \& Memory Profilers}} \\ \hline
Torch / TensorFlow Memory Tools~\cite{Torch_Tensorflow_Memory} & Meta / Google & Framework-level (Memory) & Reports GPU memory allocation, fragmentation, and utilization trends for debugging memory bottlenecks. \\ \hline
Python Profilers (cProfile, py-spy)~\cite{Python_Profilers} & Python Community & CPU-level & Measures Python-level overhead and I/O performance; used for diagnosing data preprocessing bottlenecks. \\ \hline
\end{tabular}
\end{table*}

It's important to note that tools and services exist that support different levels and infrastructures, including examples for framework-level, system-level (including CPU and GPU), kernel-level, compiler-level, communication-level, and cloud-level. 

Furthermore, we aim to provide comprehensive coverage of the AI profiling Stack, provide insights into cross-vendor and platform capabilities and offerings, and provids key feature analysis of the tools and services. 

We believe it is essential to increase awareness and use of profiling tools through AI benchmarking efforts, enabling a better understanding of bottlenecks in AI applications. Furthermore, we need to educate the community about policy limitations that may implicitly restrict specific profiling tools. One such policy restriction is that, as we saw in the last section, not all profiling information is available for energy benchmarks. Such restrictions may also be in place for some hardware profiling. 

Lastly, we need to educate the community about the {\em performance impact} of profiling costs to avoid over-profiling. Therefore, it makes sense that AI benchmarks should be able to choose the level of profiling selectively. This information is vital to support the FAIR principle and ensure that benchmarks are comparable.

